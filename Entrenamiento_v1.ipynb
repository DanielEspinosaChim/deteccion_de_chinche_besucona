{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0-2QmKsME5W",
        "outputId": "a595804b-7752-486e-b5c8-0b71a71bc91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo extraÃ­do correctamente en: /content/extracted_files\n",
            "extracted_files/\n",
            "    chincheData/\n",
            "        dataset.yaml\n",
            "        modelo.py\n",
            "        best.pt\n",
            "        val/\n",
            "            labels/\n",
            "                imagen_276.txt\n",
            "                imagen_237.txt\n",
            "                imagen_332.txt\n",
            "                imagen_254.txt\n",
            "                imagen_298.txt\n",
            "                imagen_241.txt\n",
            "                imagen_249.txt\n",
            "                imagen_258.txt\n",
            "                imagen_234.txt\n",
            "                imagen_268.txt\n",
            "                imagen_256.txt\n",
            "                imagen_242.txt\n",
            "                imagen_232.txt\n",
            "                imagen_252.txt\n",
            "                imagen_323.txt\n",
            "                imagen_239.txt\n",
            "                imagen_295.txt\n",
            "                imagen_288.txt\n",
            "                imagen_253.txt\n",
            "                imagen_264.txt\n",
            "                imagen_265.txt\n",
            "                imagen_240.txt\n",
            "                imagen_235.txt\n",
            "                imagen_271.txt\n",
            "                imagen_250.txt\n",
            "                imagen_315.txt\n",
            "                imagen_296.txt\n",
            "            images/\n",
            "                imagen_276.jpg\n",
            "                imagen_295.jpg\n",
            "                imagen_249.jpg\n",
            "                imagen_265.jpg\n",
            "                imagen_252.jpg\n",
            "                imagen_256.jpg\n",
            "                imagen_332.jpg\n",
            "                imagen_237.jpg\n",
            "                imagen_268.jpg\n",
            "                imagen_250.jpg\n",
            "                imagen_323.jpg\n",
            "                imagen_254.jpg\n",
            "                imagen_253.jpg\n",
            "                imagen_271.jpg\n",
            "                imagen_288.jpg\n",
            "                imagen_298.jpg\n",
            "                imagen_232.jpg\n",
            "                imagen_239.jpg\n",
            "                imagen_264.jpg\n",
            "                imagen_315.jpg\n",
            "                imagen_240.jpg\n",
            "                imagen_296.jpg\n",
            "                imagen_241.jpg\n",
            "                imagen_258.jpg\n",
            "                imagen_235.jpg\n",
            "                imagen_234.jpg\n",
            "                imagen_242.jpg\n",
            "        train/\n",
            "            labels/\n",
            "                imagen_74.txt\n",
            "                imagen_204.txt\n",
            "                imagen_7.txt\n",
            "                imagen_108.txt\n",
            "                imagen_215.txt\n",
            "                imagen_203.txt\n",
            "                imagen_220.txt\n",
            "                imagen_62.txt\n",
            "                imagen_194.txt\n",
            "                imagen_230.txt\n",
            "                imagen_19.txt\n",
            "                imagen_206.txt\n",
            "                imagen_98.txt\n",
            "                imagen_89.txt\n",
            "                imagen_64.txt\n",
            "                imagen_11.txt\n",
            "                imagen_213.txt\n",
            "                imagen_136.txt\n",
            "                imagen_22.txt\n",
            "                imagen_147.txt\n",
            "                imagen_222.txt\n",
            "                imagen_20.txt\n",
            "                imagen_224.txt\n",
            "                imagen_140.txt\n",
            "                imagen_145.txt\n",
            "                imagen_14.txt\n",
            "                imagen_142.txt\n",
            "                imagen_51.txt\n",
            "                imagen_174.txt\n",
            "                imagen_153.txt\n",
            "                imagen_59.txt\n",
            "                imagen_172.txt\n",
            "                imagen_221.txt\n",
            "                imagen_4.txt\n",
            "                imagen_27.txt\n",
            "                imagen_24.txt\n",
            "                imagen_103.txt\n",
            "                imagen_207.txt\n",
            "                imagen_90.txt\n",
            "                imagen_8.txt\n",
            "                imagen_77.txt\n",
            "                imagen_216.txt\n",
            "                imagen_29.txt\n",
            "                imagen_161.txt\n",
            "                imagen_148.txt\n",
            "                imagen_85.txt\n",
            "                imagen_159.txt\n",
            "                imagen_202.txt\n",
            "                imagen_25.txt\n",
            "                imagen_195.txt\n",
            "                imagen_190.txt\n",
            "                imagen_72.txt\n",
            "                imagen_131.txt\n",
            "                imagen_201.txt\n",
            "                imagen_105.txt\n",
            "                imagen_193.txt\n",
            "                imagen_124.txt\n",
            "                imagen_78.txt\n",
            "                imagen_219.txt\n",
            "                imagen_167.txt\n",
            "                imagen_26.txt\n",
            "                imagen_54.txt\n",
            "                imagen_218.txt\n",
            "                imagen_135.txt\n",
            "                imagen_212.txt\n",
            "                imagen_3.txt\n",
            "                imagen_21.txt\n",
            "                imagen_176.txt\n",
            "                imagen_126.txt\n",
            "                imagen_69.txt\n",
            "                imagen_133.txt\n",
            "                imagen_18.txt\n",
            "                imagen_121.txt\n",
            "                imagen_134.txt\n",
            "                imagen_181.txt\n",
            "                imagen_210.txt\n",
            "                imagen_179.txt\n",
            "                imagen_228.txt\n",
            "                imagen_143.txt\n",
            "                imagen_155.txt\n",
            "                imagen_66.txt\n",
            "                imagen_217.txt\n",
            "                imagen_146.txt\n",
            "                imagen_2.txt\n",
            "                imagen_209.txt\n",
            "                imagen_180.txt\n",
            "                imagen_208.txt\n",
            "                imagen_205.txt\n",
            "                imagen_223.txt\n",
            "                imagen_15.txt\n",
            "            images/\n",
            "                imagen_205.jpg\n",
            "                imagen_143.jpg\n",
            "                imagen_89.jpg\n",
            "                imagen_172.jpg\n",
            "                imagen_24.jpg\n",
            "                imagen_195.jpg\n",
            "                imagen_210.jpg\n",
            "                imagen_7.jpg\n",
            "                imagen_218.jpg\n",
            "                imagen_21.jpg\n",
            "                imagen_213.jpg\n",
            "                imagen_216.jpg\n",
            "                imagen_212.jpg\n",
            "                imagen_4.jpg\n",
            "                imagen_51.jpg\n",
            "                imagen_217.jpg\n",
            "                imagen_174.jpg\n",
            "                imagen_133.jpg\n",
            "                imagen_221.jpg\n",
            "                imagen_181.jpg\n",
            "                imagen_135.jpg\n",
            "                imagen_25.jpg\n",
            "                imagen_85.jpg\n",
            "                imagen_136.jpg\n",
            "                imagen_202.jpg\n",
            "                imagen_147.jpg\n",
            "                imagen_27.jpg\n",
            "                imagen_72.jpg\n",
            "                imagen_74.jpg\n",
            "                imagen_193.jpg\n",
            "                imagen_62.jpg\n",
            "                imagen_90.jpg\n",
            "                imagen_148.jpg\n",
            "                imagen_8.jpg\n",
            "                imagen_124.jpg\n",
            "                imagen_167.jpg\n",
            "                imagen_126.jpg\n",
            "                imagen_140.jpg\n",
            "                imagen_203.jpg\n",
            "                imagen_145.jpg\n",
            "                imagen_3.jpg\n",
            "                imagen_26.jpg\n",
            "                imagen_134.jpg\n",
            "                imagen_179.jpg\n",
            "                imagen_59.jpg\n",
            "                imagen_206.jpg\n",
            "                imagen_180.jpg\n",
            "                imagen_230.jpg\n",
            "                imagen_18.jpg\n",
            "                imagen_176.jpg\n",
            "                imagen_159.jpg\n",
            "                imagen_142.jpg\n",
            "                imagen_64.jpg\n",
            "                imagen_208.jpg\n",
            "                imagen_220.jpg\n",
            "                imagen_103.jpg\n",
            "                imagen_19.jpg\n",
            "                imagen_228.jpg\n",
            "                imagen_204.jpg\n",
            "                imagen_201.jpg\n",
            "                imagen_190.jpg\n",
            "                imagen_54.jpg\n",
            "                imagen_209.jpg\n",
            "                imagen_121.jpg\n",
            "                imagen_98.jpg\n",
            "                imagen_77.jpg\n",
            "                imagen_108.jpg\n",
            "                imagen_11.jpg\n",
            "                imagen_155.jpg\n",
            "                imagen_131.jpg\n",
            "                imagen_223.jpg\n",
            "                imagen_161.jpg\n",
            "                imagen_66.jpg\n",
            "                imagen_22.jpg\n",
            "                imagen_20.jpg\n",
            "                imagen_219.jpg\n",
            "                imagen_15.jpg\n",
            "                imagen_215.jpg\n",
            "                imagen_105.jpg\n",
            "                imagen_222.jpg\n",
            "                imagen_153.jpg\n",
            "                imagen_69.jpg\n",
            "                imagen_194.jpg\n",
            "                imagen_14.jpg\n",
            "                imagen_224.jpg\n",
            "                imagen_207.jpg\n",
            "                imagen_29.jpg\n",
            "                imagen_146.jpg\n",
            "                imagen_2.jpg\n",
            "                imagen_78.jpg\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Ruta del archivo ZIP\n",
        "zip_path = \"/content/chincheData_e.zip\"  # Ruta al archivo ZIP (ajÃºstalo si estÃ¡ en otra ubicaciÃ³n)\n",
        "extract_path = \"/content/extracted_files\"  # Carpeta donde se extraerÃ¡n los archivos\n",
        "\n",
        "# Extraer el archivo ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Archivo extraÃ­do correctamente en: {extract_path}\")\n",
        "\n",
        "# Mostrar la estructura de las carpetas extraÃ­das\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    level = root.replace(extract_path, \"\").count(os.sep)\n",
        "    indent = \" \" * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = \" \" * 4 * (level + 1)\n",
        "    for file in files:\n",
        "        print(f\"{sub_indent}{file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_-CJ99NQGC",
        "outputId": "06b235c5-57dc-4587-87dc-5d29a28ad147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.49 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fetjN_kmR048",
        "outputId": "a5e92a59-b211-43b6-d7aa-a61cf0367c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n",
            "100% 83.7M/83.7M [00:00<00:00, 231MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 972, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 738, in export\n",
            "    return Exporter(overrides=args, _callbacks=self.callbacks)(model=self.model)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 192, in __call__\n",
            "    raise ValueError(f\"Invalid export format='{fmt}'. Valid formats are {fmts}\")\n",
            "ValueError: Invalid export format='pt'. Valid formats are ('torchscript', 'onnx', 'openvino', 'engine', 'coreml', 'saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs', 'paddle', 'mnn', 'ncnn', 'imx')\n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.49 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=./extracted_files/chincheData/dataset.yaml, epochs=60, time=None, patience=100, batch=10, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 14.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/extracted_files/chincheData/train/labels... 90 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 665.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/extracted_files/chincheData/train/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/extracted_files/chincheData/val/labels... 27 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 1590.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/extracted_files/chincheData/val/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/60         0G      1.131      2.118      1.548         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [08:33<00:00, 57.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:41<00:00, 20.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.924      0.926      0.932      0.746\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/60         0G     0.9606      1.197      1.428         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [08:00<00:00, 53.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.784      0.963      0.899      0.646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/60         0G     0.9861      1.233      1.432         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:57<00:00, 53.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.493      0.704      0.618      0.363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/60         0G      1.204      1.301      1.549         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:52<00:00, 52.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.367      0.889      0.699      0.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/60         0G      1.177      1.337      1.553         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:52<00:00, 52.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.714      0.556      0.729      0.433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/60         0G      1.218      1.267      1.572         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:53<00:00, 52.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.407      0.407      0.273       0.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/60         0G      1.327      1.428      1.653         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [08:00<00:00, 53.35s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.171      0.259      0.157     0.0287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/60         0G      1.361      1.412      1.734         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:54<00:00, 52.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:41<00:00, 20.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27        0.2      0.444      0.137     0.0285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/60         0G      1.377        1.4      1.744         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:58<00:00, 53.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.201       0.63      0.217     0.0561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/60         0G      1.361      1.356      1.621         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:57<00:00, 53.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.133      0.593      0.138     0.0336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/60         0G      1.305      1.367      1.606         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:55<00:00, 52.83s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.071     0.0741     0.0157    0.00487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/60         0G       1.24      1.343       1.53         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:55<00:00, 52.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:37<00:00, 18.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.057      0.333     0.0295    0.00998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/60         0G      1.266      1.439      1.585         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:58<00:00, 53.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27     0.0757      0.185     0.0874     0.0321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/60         0G      1.364      1.316      1.684         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:55<00:00, 52.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:41<00:00, 20.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27     0.0883      0.556     0.0687      0.015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/60         0G      1.234       1.19      1.613         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:54<00:00, 52.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27     0.0635      0.222     0.0291    0.00704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/60         0G        1.2      1.154      1.522         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:55<00:00, 52.86s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:41<00:00, 20.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.243       0.38      0.213      0.103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/60         0G      1.182      1.094      1.542         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:53<00:00, 52.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.496      0.547      0.443      0.184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/60         0G      1.181      1.073      1.575         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:53<00:00, 52.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.695      0.844      0.757      0.386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/60         0G      1.182       1.07      1.531         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:52<00:00, 52.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:37<00:00, 18.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.595      0.599      0.637      0.364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/60         0G      1.178      1.103      1.523         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:52<00:00, 52.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.133      0.481      0.154     0.0818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/60         0G      1.168      1.112       1.51         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:53<00:00, 52.59s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.729      0.593      0.664      0.405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/60         0G      1.184      1.059      1.526         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:50<00:00, 52.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.559      0.593      0.572      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/60         0G      1.041      1.016      1.447         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:50<00:00, 52.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.727      0.815      0.772      0.439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/60         0G      1.112     0.9824      1.449         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:50<00:00, 52.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:40<00:00, 20.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.619      0.704      0.672      0.403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/60         0G      1.082     0.9397      1.454         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:47<00:00, 52.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.561      0.741      0.682       0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/60         0G      1.041     0.9558       1.38         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:46<00:00, 51.88s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.812      0.815      0.833      0.446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/60         0G      1.051     0.9533      1.395         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [07:47<00:00, 51.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:39<00:00, 19.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         27         27      0.841      0.889      0.886      0.559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/60         0G     0.9688     0.9165      1.364         31        640:  33%|â–ˆâ–ˆâ–ˆâ–      | 3/9 [02:34<05:09, 51.65s/it]"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Download the pre-trained model if it doesn't exist\n",
        "from pathlib import Path\n",
        "if not Path('YOLOv8l.pt').is_file():\n",
        "    !yolo export model=yolov8l.pt format=pt  # Download YOLOv8l.pt\n",
        "\n",
        "# Load pre-trained model\n",
        "model = YOLO('yolov8m.pt')  # Load the downloaded model\n",
        "\n",
        "# Train the model\n",
        "model.train(data=\"./extracted_files/chincheData/dataset.yaml\", epochs=60, imgsz=640, batch=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTAI4wKnU4vk",
        "outputId": "28e6db09-258f-4eee-8948-95bdf5cbd355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImÃ¡genes de entrenamiento: ['imagen_135.jpg', 'imagen_179.jpg', 'imagen_143.jpg', 'imagen_131.jpg', 'imagen_221.jpg', 'imagen_218.jpg', 'imagen_161.jpg', 'imagen_219.jpg', 'imagen_147.jpg', 'imagen_217.jpg', 'imagen_202.jpg', 'imagen_207.jpg', 'imagen_133.jpg', 'imagen_153.jpg', 'imagen_222.jpg', 'imagen_136.jpg', 'imagen_180.jpg', 'imagen_230.jpg', 'imagen_121.jpg', 'imagen_172.jpg', 'imagen_145.jpg', 'imagen_167.jpg', 'imagen_176.jpg', 'imagen_228.jpg', 'imagen_194.jpg', 'imagen_215.jpg', 'imagen_146.jpg', 'imagen_212.jpg', 'imagen_224.jpg', 'imagen_165.jpg', 'imagen_201.jpg', 'imagen_181.jpg', 'imagen_142.jpg', 'imagen_124.jpg', 'imagen_210.jpg', 'imagen_206.jpg', 'imagen_203.jpg', 'imagen_148.jpg', 'imagen_195.jpg', 'imagen_134.jpg', 'imagen_204.jpg', 'imagen_174.jpg', 'imagen_205.jpg', 'imagen_140.jpg', 'imagen_126.jpg', 'imagen_159.jpg', 'imagen_209.jpg', 'imagen_216.jpg', 'imagen_213.jpg', 'imagen_193.jpg', 'imagen_208.jpg', 'imagen_190.jpg', 'imagen_220.jpg', 'imagen_223.jpg', 'imagen_155.jpg']\n",
            "Etiquetas de entrenamiento: ['imagen_176.txt', 'imagen_133.txt', 'imagen_136.txt', 'imagen_155.txt', 'imagen_131.txt', 'imagen_167.txt', 'imagen_147.txt', 'imagen_220.txt', 'imagen_224.txt', 'imagen_195.txt', 'imagen_140.txt', 'imagen_153.txt', 'imagen_223.txt', 'imagen_145.txt', 'imagen_148.txt', 'imagen_181.txt', 'imagen_216.txt', 'imagen_159.txt', 'imagen_213.txt', 'imagen_218.txt', 'imagen_202.txt', 'imagen_210.txt', 'imagen_121.txt', 'imagen_194.txt', 'imagen_161.txt', 'imagen_230.txt', 'imagen_222.txt', 'imagen_217.txt', 'imagen_172.txt', 'imagen_134.txt', 'imagen_205.txt', 'imagen_219.txt', 'imagen_212.txt', 'imagen_135.txt', 'imagen_215.txt', 'imagen_146.txt', 'imagen_142.txt', 'imagen_203.txt', 'imagen_193.txt', 'imagen_143.txt', 'imagen_190.txt', 'imagen_208.txt', 'imagen_228.txt', 'imagen_179.txt', 'imagen_209.txt', 'imagen_201.txt', 'imagen_165.txt', 'imagen_221.txt', 'imagen_204.txt', 'imagen_207.txt', 'imagen_180.txt', 'imagen_206.txt', 'imagen_124.txt', 'imagen_174.txt', 'imagen_126.txt']\n",
            "ImÃ¡genes de validaciÃ³n: ['imagen_276.jpg', 'imagen_253.jpg', 'imagen_265.jpg', 'imagen_296.jpg', 'imagen_256.jpg', 'imagen_268.jpg', 'imagen_242.jpg', 'imagen_252.jpg', 'imagen_264.jpg', 'imagen_234.jpg', 'imagen_235.jpg', 'imagen_232.jpg', 'imagen_298.jpg', 'imagen_295.jpg', 'imagen_241.jpg', 'imagen_254.jpg', 'imagen_288.jpg', 'imagen_237.jpg', 'imagen_332.jpg', 'imagen_239.jpg', 'imagen_249.jpg', 'imagen_271.jpg', 'imagen_323.jpg', 'imagen_315.jpg', 'imagen_258.jpg', 'imagen_240.jpg', 'imagen_250.jpg']\n",
            "Etiquetas de validaciÃ³n: ['imagen_241.txt', 'imagen_235.txt', 'imagen_252.txt', 'imagen_295.txt', 'imagen_250.txt', 'imagen_315.txt', 'imagen_264.txt', 'imagen_332.txt', 'imagen_232.txt', 'imagen_288.txt', 'imagen_249.txt', 'imagen_242.txt', 'imagen_276.txt', 'imagen_237.txt', 'imagen_298.txt', 'imagen_256.txt', 'imagen_253.txt', 'imagen_239.txt', 'imagen_271.txt', 'imagen_240.txt', 'imagen_323.txt', 'imagen_296.txt', 'imagen_254.txt', 'imagen_268.txt', 'imagen_258.txt', 'imagen_234.txt', 'imagen_265.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Rutas de las carpetas\n",
        "train_images = \"./extracted_files/chincheData/train/images\"\n",
        "val_images = \"./extracted_files/chincheData/val/images\"\n",
        "train_labels = \"./extracted_files/chincheData/train/labels\"\n",
        "val_labels = \"./extracted_files/chincheData/val/labels\"\n",
        "\n",
        "# Listar contenido\n",
        "print(\"ImÃ¡genes de entrenamiento:\", os.listdir(train_images) if os.path.exists(train_images) else \"No encontrado\")\n",
        "print(\"Etiquetas de entrenamiento:\", os.listdir(train_labels) if os.path.exists(train_labels) else \"No encontrado\")\n",
        "print(\"ImÃ¡genes de validaciÃ³n:\", os.listdir(val_images) if os.path.exists(val_images) else \"No encontrado\")\n",
        "print(\"Etiquetas de validaciÃ³n:\", os.listdir(val_labels) if os.path.exists(val_labels) else \"No encontrado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyUq4Tz6clEz",
        "outputId": "3b51e684-a22d-40ff-e490-3cc6608395de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: No se pudo capturar el fotograma.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Cargar el modelo entrenado\n",
        "model = YOLO(\"/content/runs/detect/train11/weights/best.pt\")  # Cambia \"best.pt\" por la ruta a tu modelo si es diferente\n",
        "\n",
        "# Iniciar la captura de video desde la webcam\n",
        "cap = cv2.VideoCapture(0)  # 0 indica la webcam predeterminada\n",
        "\n",
        "# Bucle para procesar la entrada de la webcam\n",
        "while True:\n",
        "    # Capturar fotograma\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: No se pudo capturar el fotograma.\")\n",
        "        break\n",
        "\n",
        "    # Realizar la predicciÃ³n con YOLOv8\n",
        "    resultados = model.predict(frame, imgsz=640, verbose=False)  # PredicciÃ³n sin mensajes de consola\n",
        "\n",
        "    # Obtener las anotaciones con las detecciones\n",
        "    anotaciones = resultados[0].plot()  # Devuelve la imagen con las cajas y etiquetas dibujadas\n",
        "\n",
        "    # Mostrar el fotograma con las detecciones\n",
        "    cv2.imshow(\"DetecciÃ³n con YOLOv8\", anotaciones)\n",
        "\n",
        "    # Salir del programa si se presiona la tecla 'ESC' (cÃ³digo 27)\n",
        "    if cv2.waitKey(1) & 0xFF == 27:\n",
        "        break\n",
        "\n",
        "# Liberar la captura y cerrar ventanas\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF87ulFTck0s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}